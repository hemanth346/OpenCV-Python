{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing Video\n",
    "To capture a video, you need to create a VideoCapture object. \n",
    "- Its argument can be either the device index or the name of a video file. \n",
    "\n",
    "Device index is just the number to specify which camera. \n",
    "\n",
    "- Normally one camera will be connected (as in my case). So I simply pass 0 (or -1). \n",
    "\n",
    "- You can select the second camera by passing 1 and so on. After that, you can capture frame-by-frame. \n",
    "\n",
    "\n",
    "***But at the end, donâ€™t forget to release the capture.***\n",
    "\n",
    "### Reading video\n",
    "\n",
    "We use read method on the object which captures the video. **The video will be read frame-by-frame.**\n",
    "\n",
    "> object.read() \n",
    "\n",
    "- returns a tuple of 2 elements\n",
    "    1. Boolean - if the frame is present or not\n",
    "    2. Array of pixels i.e image\n",
    "    \n",
    "object.read() returns a bool (True/False). If frame is read correctly, it will be True. So you can check end of the video by checking this return value.\n",
    "\n",
    "Sometimes, object may not have initialized the capture. In that case, this code shows error. You can check whether it is initialized or not by the method object.isOpened(). If it is True, OK. Otherwise open it using object.open()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating streaming object \n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "frame = vid.read()\n",
    "\n",
    "vid.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, array([[[ 0,  4,  4],\n",
      "        [ 0,  4,  4],\n",
      "        [ 0,  3,  8],\n",
      "        ...,\n",
      "        [14,  5,  5],\n",
      "        [ 3,  6,  2],\n",
      "        [ 4,  7,  3]],\n",
      "\n",
      "       [[ 0,  3,  8],\n",
      "        [ 0,  3,  8],\n",
      "        [ 0,  2, 14],\n",
      "        ...,\n",
      "        [ 9,  2,  3],\n",
      "        [ 0,  2,  2],\n",
      "        [ 1,  3,  3]],\n",
      "\n",
      "       [[ 0,  2, 14],\n",
      "        [ 0,  2, 14],\n",
      "        [ 0,  2, 17],\n",
      "        ...,\n",
      "        [ 5,  3,  3],\n",
      "        [ 0,  2,  2],\n",
      "        [ 1,  3,  3]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1, 14,  7],\n",
      "        [ 2, 15,  8],\n",
      "        [ 2, 15,  8],\n",
      "        ...,\n",
      "        [ 0,  4, 12],\n",
      "        [ 0,  4,  9],\n",
      "        [ 0,  4,  9]],\n",
      "\n",
      "       [[ 0, 16,  8],\n",
      "        [ 0, 16,  8],\n",
      "        [ 2, 13,  6],\n",
      "        ...,\n",
      "        [ 0,  8, 11],\n",
      "        [ 0,  5, 10],\n",
      "        [ 0,  5, 10]],\n",
      "\n",
      "       [[ 1, 18, 12],\n",
      "        [ 0, 16, 10],\n",
      "        [ 4, 12,  7],\n",
      "        ...,\n",
      "        [ 0,  6,  9],\n",
      "        [ 0,  5,  8],\n",
      "        [ 0,  6,  9]]], dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video capture from file\n",
    "file = \"sample.mp4\"\n",
    "vid = cv2.VideoCapture(file)\n",
    "\n",
    "img = vid.read()\n",
    "\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, array([[[  4,   5,   0],\n",
      "        [  0,   1,   0],\n",
      "        [  0,   0,   3],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   5],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   1],\n",
      "        [  0,   0,   1],\n",
      "        [  1,   5,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [ 92, 108, 108],\n",
      "        [ 95, 109, 109],\n",
      "        [ 95, 109, 109]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [ 90, 110, 112],\n",
      "        [ 94, 109, 112],\n",
      "        [ 93, 108, 111]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [ 90, 110, 112],\n",
      "        [ 94, 109, 112],\n",
      "        [ 92, 107, 110]]], dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video capture from file\n",
    "file = \"sample_1.mp4\" #No video file\n",
    "vid = cv2.VideoCapture(file)\n",
    "\n",
    "img_1 = vid.read()\n",
    "\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, None)\n"
     ]
    }
   ],
   "source": [
    "print(img_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing Video \n",
    "\n",
    "We can use while loop and show image frames until asked to stop \n",
    "\n",
    "### from file\n",
    "\n",
    "It is same as capturing from Camera, just change camera index with video file name. \n",
    "\n",
    "Also while displaying the frame, use appropriate time for cv2.waitKey(). \n",
    "\n",
    "- If it is too less, video will be very fast and \n",
    "- if it is too high, video will be slow \n",
    "    - Well, that is how you can display videos in slow motion\n",
    "    - 25 milliseconds will be OK in normal cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/35372700/whats-0xff-for-in-cv2-waitkey1\n",
    "\n",
    "cv2.waitKey() returns a 32 Bit integer value (might be dependent on the platform). The key input is in ASCII which is an 8 Bit integer value. So you only care about these 8 bits and want all other bits to be 0. This you can achieve with &\n",
    "\n",
    "By using bitwise AND (&) with this constant, it leaves only the last 8 bits of the original (in this case, whatever cv2.waitKey(0) is)\n",
    "- 0xFF is a hexadecimal constant which is 11111111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#playing directly from camera\n",
    "\n",
    "cap = cv2.VideoCapture(0) #for primary video capture device\n",
    "fcount = 0 #frames count, just to check\n",
    "\n",
    "if (cap.isOpened() is False): \n",
    "    print(\"Error opening stream\")\n",
    "\n",
    "fcount = 0\n",
    "while (cap.isOpened()):\n",
    "    (check, frame) = cap.read()\n",
    "    fcount += 1\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #converting video to grayscale\n",
    "    \n",
    "    if fcount == 200: #temporary break as notebook have trouble with cv2.waitKey\n",
    "        break\n",
    "#    cv2.imshow('frame',gray)\n",
    "    \n",
    "#    key = cv2.waitKey(1) & 0xFF \n",
    "#    if key == ord(\"q\"):  #To stop streaming\n",
    "#        break\n",
    "    \n",
    "cap.release()\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "#playing from File\n",
    "\n",
    "#Not running below as notebook are not able to run close cv2 windows\n",
    "file = 'sample.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(file)\n",
    "\n",
    "if (cap.isOpened() is False): \n",
    "    print(\"Error opening file\")\n",
    "\n",
    "fcount = 0\n",
    "while (cap.isOpened()):\n",
    "    (check,frame) = cap.read()\n",
    "    # to come out of loop once video ends\n",
    "    if check is False: #or if frame == None:\n",
    "        break\n",
    "\n",
    "    fcount += 1\n",
    "#    #To stop in the middle of the video\n",
    "#    key = cv2.waitKey(1) & 0xFF \n",
    "#    if key == ord(\"q\"):\n",
    "#        break\n",
    "\n",
    "#    cv2.imshow('frame',frame)\n",
    "#    cv2.waitKey(25) #if wait time is high it becomes slow motion, if it very low it becomes time lapse\n",
    "print(fcount)\n",
    "\n",
    "cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a Video\n",
    "\n",
    "For images, it is very simple, just use cv2.imwrite(). Here a little more work is required.\n",
    "\n",
    "This time we create a VideoWriter object. \n",
    "1. We should specify the output file name (eg: output.avi). \n",
    "2. Then we should specify the FourCC code \n",
    "3. Then number of frames per second (fps) and \n",
    "4. frame size should be passed. \n",
    "5. And last one is isColor flag. If it is True, encoder expect color frame, otherwise it works with grayscale frame.\n",
    "\n",
    "\n",
    "***FourCC is a 4-byte code used to specify the video codec. The list of available codes can be found in fourcc.org. It is platform dependent.*** \n",
    "\n",
    "Some example codecs\n",
    "\n",
    "    - In Fedora: DIVX, XVID, MJPG, X264, WMV1, WMV2. (XVID is more preferable. MJPG results in high size video. X264 gives very small size video)\n",
    "    - In Windows: DIVX (More to be tested and added)\n",
    "\n",
    "- #### FourCC code is passed as cv2.VideoWriter_fourcc('M','J','P','G') or cv2.VideoWriter_fourcc(*'MJPG') for MJPG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'MPG4')\n",
    "#out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "#if not (cap.isOpened()):\n",
    "#    print(\"Error reading feed\")\n",
    "#while(cap.isOpened()):\n",
    "#    check, frame = cap.read()\n",
    "#    if check is False:\n",
    "#        break\n",
    "    \n",
    "#    frame = cv2.flip(frame,0)\n",
    "    # write the flipped frame\n",
    "#    out.write(frame)\n",
    "\n",
    "#    cv2.imshow('frame',frame)\n",
    "#    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "#cap.release()\n",
    "#out.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- codecs must be available on your system at runtime and doesn't depends on OpenCV but depends on codec you have installed on your system. This means that the codec must be available on the machine that runs the OpenCV application.\n",
    "\n",
    "OpenCV doesn't have a function to get the list of available codecs. To a get list of available codecs you need to call some system function. On Windows, OpenCV just calls the function that pup up the OS codec form.\n",
    "\n",
    "- The CV_FOURCC('M','J','P','G') codec should be supported natively by OpenCV (no need of external library)\n",
    "\n",
    "***BTW each codec follows some specs (frame size or ratio, fps, compression ...) thus if your app provides codec selection you have to manage codec specs too.***\n",
    "\n",
    "\n",
    "Remember that on Windows, cv::VideoWriter uses MJPG or VFW API (Video For Windows) thus MJPG codec or any available codec that is VFW compliant can be used with VideoWriter.\n",
    "\n",
    "To check for installed Video Codecs on your system:\n",
    "\n",
    "    just run Windows Media Player, enable the menu bar than About > Technical Info \n",
    "    file:///C:/Users/kaheman/AppData/Local/Temp/wmpsupport.htm\n",
    "\n",
    "    OR run MSINFO32.exe than components > Multimedia > Codec video\n",
    "    \n",
    "Sometimes, even when the specific codec is available, OpenCV may not be able to use it. MJPG is a safe choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
